{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ray Features Demo Notebook\n",
    "\n",
    "This notebook demonstrates key features of the Ray cluster including:\n",
    "- Basic Ray tasks and actors\n",
    "- GPU utilization\n",
    "- Autoscaling behavior\n",
    "- Resource management\n",
    "- Common patterns and best practices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Connect to Ray Cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "import ray\n",
    "import time\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "# Connect to the Ray cluster\n",
    "ray.init(address='ray://ray-cluster-head-svc.ray-system.svc:10001')\n",
    "\n",
    "# Print cluster resources\n",
    "print(\"Cluster Resources:\")\n",
    "print(ray.cluster_resources())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Basic Ray Tasks\n",
    "\n",
    "Demonstrate basic task parallelization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "@ray.remote\n",
    "def compute_heavy(n):\n",
    "    time.sleep(1)  # Simulate computation\n",
    "    return n * n\n",
    "\n",
    "# Sequential execution\n",
    "start_time = time.time()\n",
    "regular_result = [compute_heavy.bind(i) for i in range(10)]\n",
    "print(f\"Sequential time: {time.time() - start_time:.2f} seconds\")\n",
    "\n",
    "# Parallel execution\n",
    "start_time = time.time()\n",
    "futures = [compute_heavy.remote(i) for i in range(10)]\n",
    "parallel_result = ray.get(futures)\n",
    "print(f\"Parallel time: {time.time() - start_time:.2f} seconds\")\n",
    "\n",
    "print(\"\\nResults are the same:\", regular_result == parallel_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. GPU Tasks\n",
    "\n",
    "Demonstrate GPU utilization with PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "@ray.remote(num_gpus=1)\n",
    "def gpu_task():\n",
    "    # Create a large tensor on GPU\n",
    "    tensor = torch.randn(1000, 1000, device='cuda')\n",
    "    # Perform some GPU operations\n",
    "    result = torch.mm(tensor, tensor)\n",
    "    return {\n",
    "        'gpu_available': torch.cuda.is_available(),\n",
    "        'gpu_device': torch.cuda.current_device(),\n",
    "        'gpu_name': torch.cuda.get_device_name(),\n",
    "        'tensor_device': tensor.device\n",
    "    }\n",
    "\n",
    "# Run GPU task\n",
    "result = ray.get(gpu_task.remote())\n",
    "print(\"GPU Task Results:\")\n",
    "for k, v in result.items():\n",
    "    print(f\"{k}: {v}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Ray Actors\n",
    "\n",
    "Demonstrate stateful computations with actors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "@ray.remote\n",
    "class Counter:\n",
    "    def __init__(self):\n",
    "        self.value = 0\n",
    "        \n",
    "    def increment(self):\n",
    "        self.value += 1\n",
    "        return self.value\n",
    "    \n",
    "    def get_value(self):\n",
    "        return self.value\n",
    "\n",
    "# Create actor instances\n",
    "counters = [Counter.remote() for _ in range(4)]\n",
    "\n",
    "# Increment counters in parallel\n",
    "futures = []\n",
    "for _ in range(5):  # 5 rounds of increments\n",
    "    for counter in counters:\n",
    "        futures.append(counter.increment.remote())\n",
    "\n",
    "# Get final values\n",
    "final_values = ray.get([counter.get_value.remote() for counter in counters])\n",
    "print(\"Final counter values:\", final_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Testing Autoscaling\n",
    "\n",
    "Create enough tasks to trigger autoscaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "@ray.remote(num_cpus=1)\n",
    "def cpu_intensive_task(task_id):\n",
    "    # Simulate CPU-intensive work\n",
    "    time.sleep(2)\n",
    "    return f\"Task {task_id} completed\"\n",
    "\n",
    "print(\"Initial cluster resources:\")\n",
    "print(ray.cluster_resources())\n",
    "\n",
    "# Submit many tasks to trigger autoscaling\n",
    "futures = [cpu_intensive_task.remote(i) for i in range(20)]\n",
    "\n",
    "# Process results as they complete\n",
    "while futures:\n",
    "    done_id, futures = ray.wait(futures)\n",
    "    result = ray.get(done_id[0])\n",
    "    print(result)\n",
    "    print(\"Current cluster resources:\")\n",
    "    print(ray.cluster_resources())\n",
    "    time.sleep(0.5)  # Small delay to see scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Resource Management\n",
    "\n",
    "Demonstrate proper resource specification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "@ray.remote(num_cpus=0.5, num_gpus=0.5)\n",
    "def partial_resource_task():\n",
    "    # This task uses half a CPU and half a GPU\n",
    "    time.sleep(1)\n",
    "    return \"Completed with partial resources\"\n",
    "\n",
    "@ray.remote(num_cpus=1, num_gpus=1)\n",
    "def full_resource_task():\n",
    "    # This task uses a full CPU and GPU\n",
    "    time.sleep(1)\n",
    "    return \"Completed with full resources\"\n",
    "\n",
    "# Run mixed resource tasks\n",
    "partial_futures = [partial_resource_task.remote() for _ in range(4)]\n",
    "full_futures = [full_resource_task.remote() for _ in range(2)]\n",
    "\n",
    "# Get results\n",
    "partial_results = ray.get(partial_futures)\n",
    "full_results = ray.get(full_futures)\n",
    "\n",
    "print(\"Partial resource task results:\", partial_results)\n",
    "print(\"Full resource task results:\", full_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Clean Up\n",
    "\n",
    "Proper cleanup of Ray resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Disconnect from the Ray cluster\n",
    "ray.shutdown()\n",
    "print(\"Disconnected from Ray cluster\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
